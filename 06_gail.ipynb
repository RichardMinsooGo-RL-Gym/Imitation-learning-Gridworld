{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Xs9ipDI8nb1"
      },
      "source": [
        "# Generative Adversarial Imitation Learning (GAIL)\n",
        "\n",
        "Generative Adversarial Imitation Learning (GAIL) is the method inspired by IRL (Inverse Reinforcement Learning) and GANs (Generative Adversarial Networks), in which discriminator network is used to distinguish true data from false data.\n",
        "\n",
        "Unlike previous IRL methods, GAIL constrains the behavior of the agent to be approximately optimal without explicitly recovering the reward's function, i.e, it scales an IRL approach by bypassing intermediate IRL steps (bypassing steps for learning a cost or reward function).<br>\n",
        "It directly extracts a policy from data, **as if it were obtained by reinforcement learning following inverse\n",
        "reinforcement learning**. (RL algorithms discussed in [here](https://github.com/tsmatz/reinforcement-learning-tutorials) can also be applied in GAIL.)\n",
        "\n",
        "Up until now, we assumed that the rewards $\\mathbf{w}$ is linear to the feature of trajectory, $\\verb|reward| = \\mathbf{w}^T \\cdot \\phi(\\tau)$.<br>\n",
        "GAIL, however, doesn't need this constraint, and can then imitate arbitrarily complex expert behaviors.\n",
        "\n",
        "GAIL is one of SOTA (state-of-the-art) imitation learning algorithms.\n",
        "\n",
        "*(back to [index](https://github.com/tsmatz/imitation-learning-tutorials/))*"
      ],
      "id": "-Xs9ipDI8nb1"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(np.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSz1KN7A0kyi",
        "outputId": "7ed53ef8-ec89-4563-be86-8f66e80089c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.2\n"
          ]
        }
      ],
      "id": "PSz1KN7A0kyi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TpZufgx1veLO"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "id": "TpZufgx1veLO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "autMsTegxadV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e85316d-1230-454d-c105-68a80edd1078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "get_ipython().system('pip install torch numpy')"
      ],
      "id": "autMsTegxadV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZaWwPFttIVXg",
        "outputId": "c3436f89-b8bf-4e2d-c70e-2df5ba270cbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mhint: Using 'master' as the name for the initial branch. This default branch name\u001b[m\n",
            "\u001b[33mhint: is subject to change. To configure the initial branch name to use in all\u001b[m\n",
            "\u001b[33mhint: of your new repositories, which will suppress this warning, call:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit config --global init.defaultBranch <name>\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: Names commonly chosen instead of 'master' are 'main', 'trunk' and\u001b[m\n",
            "\u001b[33mhint: 'development'. The just-created branch can be renamed via this command:\u001b[m\n",
            "\u001b[33mhint: \u001b[m\n",
            "\u001b[33mhint: \tgit branch -m <name>\u001b[m\n",
            "Initialized empty Git repository in /content/.git/\n",
            "remote: Enumerating objects: 141, done.\u001b[K\n",
            "remote: Counting objects: 100% (141/141), done.\u001b[K\n",
            "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
            "remote: Total 141 (delta 90), reused 76 (delta 34), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (141/141), 1.45 MiB | 5.27 MiB/s, done.\n",
            "Resolving deltas: 100% (90/90), done.\n",
            "From https://github.com/tsmatz/imitation-learning-tutorials\n",
            " * branch            master     -> FETCH_HEAD\n",
            " * [new branch]      master     -> origin/master\n"
          ]
        }
      ],
      "source": [
        "# Clone from Github Repository\n",
        "! git init .\n",
        "! git remote add origin https://github.com/RichardMinsooGo-RL-Gym/Imitation-learning-Gridworld.git\n",
        "! git pull origin master\n",
        "# ! git pull origin main"
      ],
      "id": "ZaWwPFttIVXg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ynBGmx68nb7"
      },
      "source": [
        "## Overview of Generative Adversarial Imitation Learning (GAIL) method\n",
        "\n",
        "Let's briefly follow theoretical aspects behind GAIL algorithm along with the original paper [[Ho and Ermon, 2016](https://arxiv.org/pdf/1606.03476)].\n",
        "\n",
        "Maximum Causal Entropy (MCE) IRL is one of successful IRL algorithms.<br>\n",
        "As we have discussed in [MCE IRL example](./04_mce_irl.ipynb), Maximum Causal Entropy IRL finds a cost function (see below note) to maximize the entropy $-H(\\pi)$ and expectation.<br>\n",
        "IRL operation in abstraction can then be written as :\n",
        "\n",
        "$\\displaystyle IRL(\\pi_E) = \\max_{c \\in \\mathcal{C}} \\left( \\min_{\\pi \\in \\Pi} \\left( -H(\\pi) + \\mathbb{E}_{\\pi}[c(s,a)] \\right) - \\mathbb{E}_{\\pi_E}[c(s,a)] \\right)$\n",
        "\n",
        "where $\\mathcal{C}$ is a set of cost functions.\n",
        "\n",
        "> Note : Unlike [MCE IRL example](./04_mce_irl.ipynb), the function $c()$ is not a reward function, but a cost function. The cost function is **minimized (not maximized)** for optimization.\n",
        "\n",
        "To prevent from [overfitting](https://tsmatz.wordpress.com/2017/09/13/overfitting-for-regression-and-deep-learning/) in machine learning problems, we introduce a regularizer, $\\psi : \\mathbb{R}^{\\mathcal{S} \\times \\mathcal{A}} \\to \\mathbb{R} \\cup \\{ \\infty \\}$, and apply in this equation. :\n",
        "\n",
        "$\\displaystyle IRL_{\\psi}(\\pi_E) = \\arg \\max_{c \\in \\mathbb{R}^{\\mathcal{S} \\times \\mathcal{A}}} \\left( -\\psi(c) + \\min_{\\pi \\in \\Pi} \\left( -H(\\pi) + \\mathbb{E}_{\\pi}[c(s,a)] \\right) - \\mathbb{E}_{\\pi_E}[c(s,a)] \\right) \\;\\;\\;\\;\\;\\; (1) $\n",
        "\n",
        "Now we introduce the occupancy measure which is often used in the theory of RL.\n",
        "\n",
        "First, we define the occupancy measure $\\rho_{\\pi}(s, a) : \\mathcal{S} \\times \\mathcal{A} \\to \\mathbb{R}$ for $\\pi$ as :\n",
        "\n",
        "$\\displaystyle \\rho_{\\pi}(s, a) \\coloneqq \\pi(a | s) \\sum_{t=0}^{\\infty} \\gamma^t P(s_t=s|\\pi) $\n",
        "\n",
        "> Note : $P(s_t=s|\\pi)$ is the probability of landing in state $s$.\n",
        "\n",
        "In abstraction, the occupancy measure is the probability of state's occurrence when navigating the environment with policy $\\pi$.\n",
        "\n",
        "When we denote a set of valid occupancy measures $\\{ \\rho_{\\pi} : \\pi \\in \\Pi \\}$ as $\\mathcal{D}$, it's known that there is a one-to-one correspondence between $\\Pi$ and $\\mathcal{D}$. (i.e, When some $\\rho$ is given, the corresponding $\\pi$ to satisfy $\\rho = \\rho_\\pi$ is uniquely determined.)\n",
        "\n",
        "Using occupancy measures, it's known that to find the optimal $\\pi$ under a cost function obtained in (1) is equivalent to :\n",
        "\n",
        "$\\displaystyle RL \\circ IRL_{\\psi}(\\pi_E) = \\arg \\min_{\\pi \\in \\Pi} \\left( -H(\\pi) + \\psi^* \\left( \\rho_{\\pi} - \\rho_{\\pi_E} \\right) \\right) \\;\\;\\;\\;\\;\\; (2)$\n",
        "\n",
        "where $\\psi^* : \\mathbb{R}^{\\mathcal{S} \\times \\mathcal{A}} \\to \\mathbb{R} \\cup \\{ \\infty \\}$ is the [convex conjugate](https://en.wikipedia.org/wiki/Convex_conjugate) of $\\psi$.\n",
        "\n",
        "Especially, when $\\psi$ is constant and $\\pi$ is then obtained by (2), it's known that $\\rho_{\\pi} = \\rho_{\\pi_E}$.\n",
        "\n",
        "> Note : See [original paper](https://arxiv.org/pdf/1606.03476) and its Appendix A.1 for this proof.\n",
        "\n",
        "This implicitly means that $\\psi$-regularized IRL is to seek a policy whose occupancy measure is close to the expert, as measured by the convex function $\\psi^*$. If $\\psi$ is constant, the solution of (2) simply matches occupancy measures with expert at all states and actions.<br>\n",
        "Here I don't go so far into details, but it's also known that the expectation matching with linear cost function (which are discussed in previous examples) is the special case of above (2). (See description about apprenticeship learning in [original paper](https://arxiv.org/pdf/1606.03476) for details.)\n",
        "\n",
        "Now let $\\psi_{GA}()$ be the following regularization function. :\n",
        "\n",
        "$\\displaystyle \\psi_{GA}(c) \\coloneqq \\mathbb{E}_{\\pi_E}[g(c(s,a))] $  when $c \\lt 0$\n",
        "\n",
        "$\\displaystyle \\psi_{GA}(c) \\coloneqq +\\infty $  otherwise\n",
        "\n",
        "where\n",
        "\n",
        "$\\displaystyle g(x) \\coloneqq -x-\\log(1-e^x) $  when $x \\lt 0$\n",
        "\n",
        "$\\displaystyle g(x) \\coloneqq +\\infty $  otherwise\n",
        "\n",
        "This regularization forces that the cost function $c$ is always negative, and penalitizes for small $c$ and large $c$ (close to zero), because the plot of function $g(x)$ is as follows. :\n",
        "\n",
        "<img src=\"./assets/regularization_plot.png\" alt=\"Regularization Plot\" width=\"300\"/>\n",
        "\n",
        "Unlike linear cost functions (or linear reward functions) seen in previous IRL examples, $\\psi_{GA}()$ allows for any cost function, as long as it is negative everywhere, and $RL \\circ IRL_{\\psi}(\\pi_E)$ can be fitted to more complex cost estimation.\n",
        "\n",
        "Under this assumption, it's known that it holds the following equation. (See [original paper](https://arxiv.org/pdf/1606.03476) for the proof.)\n",
        "\n",
        "$\\displaystyle \\psi_{GA}^* (\\rho_{\\pi} - \\rho_{\\pi_E}) = \\max_{D \\in (0,1)^{\\mathcal{S} \\times \\mathcal{A}}} \\left( \\mathbb{E}_{\\pi} [\\log(D(s, a))] + \\mathbb{E}_{\\pi_E} [\\log(1 - D(s, a))] \\right) \\;\\;\\;\\;\\;\\; (3) $\n",
        "\n",
        "where $D$ is discriminative classifier $D : \\mathcal{S} \\times \\mathcal{A} \\to (0,1)$.\n",
        "\n",
        "Now we assume that the learner's policy $\\pi$ is parameterized by $\\theta$ (i.e, $\\pi = \\pi_{\\theta}$) and the discriminator network $D$ is parameterized by $w$ (i.e, $D = D_w$).\n",
        "\n",
        "By above (2) and (3), our algorithm (GAIL) is to alternately update $w$ and $\\theta$ as follows. :\n",
        "\n",
        "- Update $w$ to increase $\\mathbb{E}_{\\pi} [\\log(D(s, a))] + \\mathbb{E}_{\\pi_E} [\\log(1 - D(s, a))]$.\n",
        "- Update $\\theta$ to decrease $\\mathbb{E}_{\\pi} [\\log(D(s, a))] - \\lambda H(\\pi) $ using the updated discriminator $D(s,a)$, where $\\lambda \\geq 0$ is a controlling coefficient.\n",
        "\n",
        "In [original paper](https://arxiv.org/pdf/1606.03476), Adam gradient step is applied to update $w$, and TRPO (trust region policy optimization) algorithm is used to update $\\theta$ in order to avoid unstable policy updates.<br>\n",
        "As you'll see later, we'll however use PPO (proximal policy optimization) instead of TRPO in this example."
      ],
      "id": "0ynBGmx68nb7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gdS3nNY8nb9"
      },
      "source": [
        "## Implementation"
      ],
      "id": "0gdS3nNY8nb9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfnD00HZ8nb-"
      },
      "source": [
        "### 1. Restore environment and load expert's data"
      ],
      "id": "rfnD00HZ8nb-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P68pe1VR8nb-"
      },
      "source": [
        "Before we start, we need to install the required packages."
      ],
      "id": "P68pe1VR8nb-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFm7uhN18nb_",
        "outputId": "a4d61d84-01a2-4276-e89b-3f4fec5d0e91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch numpy matplotlib"
      ],
      "id": "gFm7uhN18nb_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzSkWxll8ncB"
      },
      "source": [
        "Firstly, I restore GridWorld environment from JSON file. (See [this script](./00_generate_expert_trajectories.ipynb) for generating the same environment.)\n",
        "\n",
        "I note that I'll apply temporal difference (TD) learning (see [here](https://github.com/tsmatz/reinforcement-learning-tutorials/blob/master/03-actor-critic.ipynb)) in this example, and the difference between termination and truncation is important.<br>\n",
        "Thus, by setting ```max_timestep=None```, the truncation is not performed in this environment, and I'll handle the truncation during the training by myself."
      ],
      "id": "yzSkWxll8ncB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZoWOm1Q8ncD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import json\n",
        "from gridworld import GridWorld\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "with open(\"gridworld.json\", \"r\") as f:\n",
        "    json_object = json.load(f)\n",
        "    env = GridWorld(**json_object, max_timestep=None, device=device)"
      ],
      "id": "mZoWOm1Q8ncD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-QU7tJD8ncE"
      },
      "source": [
        "Now I visualize our GridWorld environment.\n",
        "\n",
        "The number in each cell indicates the reward score on this state.<br>\n",
        "The goal state is on the right-bottom corner (in which the reward is ```10.0```), and the initial state is uniformly picked up from the gray-colored cells.<br>\n",
        "If the agent can reach to goal state without losing any rewards, it will get ```10.0``` for total reward.\n",
        "\n",
        "See [Readme.md](https://github.com/tsmatz/imitation-learning-tutorials/blob/master/Readme.md) for details about the game rule of this environment."
      ],
      "id": "F-QU7tJD8ncE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7NWd4Ky18ncE",
        "outputId": "f5c69fe1-d1c8-47aa-d2c6-83d41466c8b1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table><tr><td>0</td><td>-1</td><td>0</td><td>0</td><td>0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>-1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>0</td><td>-1</td><td>-1</td><td>0</td><td>0</td><td>0</td><td>-1</td><td>-1</td><td>0</td><td>0</td><td>-1</td><td>-1</td></tr><tr><td>0</td><td>0</td><td>-1</td><td>-1</td><td>0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>-1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>0</td><td>0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>-1</td></tr><tr><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>0</td><td>0</td><td>-1</td><td>0</td><td>-1</td><td>-1</td><td>0</td><td>0</td></tr><tr><td>0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>0</td><td>-1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>-1</td></tr><tr><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>0</td><td>0</td><td>0</td><td>-1</td><td>0</td><td>-1</td><td>0</td><td>-1</td><td>-1</td></tr><tr><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>0</td><td>0</td><td>-1</td><td>0</td><td>-1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>0</td><td>-1</td><td>0</td><td>0</td><td>0</td><td>-1</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>-1</td><td>-1</td><td>0</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>0</td><td>0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td></tr><tr><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td></tr><tr><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td></tr><tr><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td></tr><tr><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td></tr><tr><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>0</td><td>-1</td><td>0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>0</td><td>-1</td></tr><tr><td>0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>0</td><td>-1</td><td>0</td><td>-1</td><td>0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>0</td><td>0</td><td>-1</td><td>0</td><td>0</td><td>0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td></tr><tr><td>0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>0</td><td>0</td><td>-1</td><td>0</td><td>0</td><td>0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>0</td></tr><tr><td>0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td></tr><tr><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td></tr><tr><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>0</td><td>0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td></tr><tr><td>0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td></tr><tr><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td></tr><tr><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td></tr><tr><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td></tr><tr><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td></tr><tr><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td></tr><tr><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td></tr><tr><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td></tr><tr><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td></tr><tr><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>0</td><td>0</td><td>0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td></tr><tr><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td>0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td></tr><tr><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td></tr><tr><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td></tr><tr><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td></tr><tr><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td></tr><tr><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td></tr><tr><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td></tr><tr><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td></tr><tr><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td></tr><tr><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td></tr><tr><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td></tr><tr><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td></tr><tr><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td></tr><tr><td>-1</td><td>0</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td></tr><tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td></tr><tr><td>0</td><td>0</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td>0</td><td>0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td>-1</td><td>0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td></tr><tr><td>-1</td><td>0</td><td>0</td><td>-1</td><td>-1</td><td>0</td><td>-1</td><td>0</td><td>0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td></tr><tr><td>-1</td><td>0</td><td>0</td><td>0</td><td>-1</td><td>0</td><td>-1</td><td>-1</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td>-1</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">0</td><td bgcolor=\"gray\">0</td><td>-1</td><td bgcolor=\"gray\">10</td></tr></table>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "valid_states_all = torch.cat((env.valid_states, torch.tensor([env.grid_size-1,env.grid_size-1]).to(device).unsqueeze(dim=0)))\n",
        "valid_states_all = valid_states_all[:,0] * env.grid_size + valid_states_all[:,1]\n",
        "\n",
        "html_text = \"<table>\"\n",
        "for row in range(env.grid_size):\n",
        "    html_text += \"<tr>\"\n",
        "    for col in range(env.grid_size):\n",
        "        if row*env.grid_size + col in valid_states_all:\n",
        "            html_text += \"<td bgcolor=\\\"gray\\\">\"\n",
        "        else:\n",
        "            html_text += \"<td>\"\n",
        "        html_text += str(env.reward_map[row*env.grid_size+col].tolist())\n",
        "        html_text += \"</td>\"\n",
        "    html_text += \"</tr>\"\n",
        "html_text += \"</table>\"\n",
        "\n",
        "display(HTML(html_text))"
      ],
      "id": "7NWd4Ky18ncE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQ-Ih_aM8ncG"
      },
      "source": [
        "Load expert's data (demonstrations) which is saved in ```./expert_data``` folder in this repository.\n",
        "\n",
        "> Note : See [this script](./00_generate_expert_trajectories.ipynb) for generating expert dataset."
      ],
      "id": "bQ-Ih_aM8ncG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJH02Nw_8ncG"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "dest_dir = \"./expert_data\"\n",
        "checkpoint_file = \"ckpt0.pkl\"\n",
        "\n",
        "# load expert data from pickle\n",
        "with open(f\"{dest_dir}/{checkpoint_file}\", \"rb\") as f:\n",
        "    exp_data = pickle.load(f)\n",
        "exp_states = torch.tensor(exp_data[\"states\"]).to(device)\n",
        "exp_actions = torch.tensor(exp_data[\"actions\"]).to(device)\n",
        "timestep_lens = exp_data[\"timestep_lens\"]"
      ],
      "id": "ZJH02Nw_8ncG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3THZEnR8ncH"
      },
      "source": [
        "### 2. Create networks\n",
        "\n",
        "Now I define the following policy network $\\pi_{\\theta}$, value network, and discriminator network $D_w$.<br>\n",
        "In TRPO (also, PPO) implementation, not only the policy network, but the value network is also required.\n",
        "\n",
        "- Policy network : It receives one-hot state as input. It then returns the optimal action logits as output.\n",
        "- Value network : It receives one-hot state as input. It then returns a single value as output.\n",
        "- Discriminator network : It receives one-hot state and one-hot action as input. It then returns a value of range (0, 1)."
      ],
      "id": "l3THZEnR8ncH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3-8h03t8ncH"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "STATE_SIZE = env.grid_size*env.grid_size  # 2500\n",
        "ACTION_SIZE = env.action_size             # 4\n",
        "\n",
        "#\n",
        "# Define model\n",
        "#\n",
        "class PolicyNet(nn.Module):\n",
        "    def __init__(self, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.hidden = nn.Linear(STATE_SIZE, hidden_dim)\n",
        "        self.output = nn.Linear(hidden_dim, 4)\n",
        "\n",
        "    def forward(self, s):\n",
        "        outs = self.hidden(s)\n",
        "        outs = F.relu(outs)\n",
        "        logits = self.output(outs)\n",
        "        return logits\n",
        "\n",
        "class ValueNet(nn.Module):\n",
        "    def __init__(self, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.hidden = nn.Linear(STATE_SIZE, hidden_dim)\n",
        "        self.output = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, s):\n",
        "        outs = self.hidden(s)\n",
        "        outs = F.relu(outs)\n",
        "        value = self.output(outs)\n",
        "        return value\n",
        "\n",
        "class DiscriminatorNet(nn.Module):\n",
        "    def __init__(self, hidden_dim=64):\n",
        "        super().__init__()\n",
        "        self.hidden1 = nn.Linear(STATE_SIZE + ACTION_SIZE, hidden_dim)\n",
        "        self.hidden2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.get_logits = nn.Linear(hidden_dim, 1)\n",
        "        self.get_sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, s):\n",
        "        outs = self.hidden1(s)\n",
        "        outs = F.relu(outs)\n",
        "        outs = self.hidden2(outs)\n",
        "        outs = F.relu(outs)\n",
        "        logits = self.get_logits(outs)\n",
        "        output = self.get_sigmoid(logits)\n",
        "        return output\n",
        "\n",
        "#\n",
        "# Generate model\n",
        "#\n",
        "policy_func = PolicyNet().to(device)\n",
        "value_func = ValueNet().to(device)\n",
        "discriminator = DiscriminatorNet().to(device)"
      ],
      "id": "V3-8h03t8ncH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRtJ4S4P8ncI"
      },
      "source": [
        "### 3. Create functions to get learner and expert data"
      ],
      "id": "IRtJ4S4P8ncI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7o8uwgB8ncI"
      },
      "source": [
        "Now we create a function to get expert samples.<br>\n",
        "In this example, we get 6000 samples (6000 steps) at a time."
      ],
      "id": "T7o8uwgB8ncI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWn3A7av8ncI"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import itertools\n",
        "\n",
        "num_samples = 6000\n",
        "\n",
        "expert_loader = DataLoader(\n",
        "    list(zip(exp_states, exp_actions)),\n",
        "    batch_size=num_samples,\n",
        "    shuffle=False,\n",
        ")\n",
        "expert_iter = iter(itertools.cycle(expert_loader))\n",
        "\n",
        "def get_data_by_expert(num_samples=num_samples):\n",
        "    data_length = 0\n",
        "    while data_length < num_samples:\n",
        "        states, actions = next(expert_iter)\n",
        "        data_length = len(states)\n",
        "    return states, actions"
      ],
      "id": "IWn3A7av8ncI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjVmrJtJ8ncJ"
      },
      "source": [
        "Not only sampling by the expert, but sampling by policy $\\pi$ is also required, because we need the expectation $\\mathbb{E}_{\\pi}(\\cdot)$.\n",
        "\n",
        "In sampling by policy $\\pi$, we need values and advantages for applying TRPO (or PPO) algorithm.\n",
        "\n",
        "> Note : See [here](https://github.com/tsmatz/reinforcement-learning-tutorials/blob/master/03-actor-critic.ipynb) for theoretical aspects of values and advantages in RL.\n",
        "\n",
        "In this example, I'll use TD (temporal difference) and GAE (generalized advantage estimation) for getting values and advantages in TRPO (or PPO).\n",
        "\n",
        "Here I then briefly summarize TD and GAE.\n",
        "\n",
        "Suppose, $V(\\cdot)$ is the value network.<br>\n",
        "In TD (temporal difference), we get the value at time-step $t$ by $r_t + \\gamma V(s_{t+1})$, where $r_t$ is a real score at $t$. (I note that $r_t = \\log(D(s_t, a_t))$ in this example.)<br>\n",
        "We then get value's difference (between value and estimated value) $\\delta_t^V$ by :\n",
        "\n",
        "$\\displaystyle \\delta_t^V \\coloneqq r_t + \\gamma V(s_{t+1}) - V(s_t)$\n",
        "\n",
        "In [GAE (generalized advantage estimation)](https://arxiv.org/pdf/1506.02438), the advantage at $t$ is obtained by :\n",
        "\n",
        "$\\displaystyle \\hat{A}_t^{\\verb|GAE|} \\coloneqq \\sum_{l=0}^{\\infty} (\\gamma \\lambda_{\\verb|GAE|})^l \\delta_{t+l}^V$\n",
        "\n",
        "where $\\lambda_{\\verb|GAE|} \\in [0, 1]$ is a controlling parameter (between bias and variance) in GAE.\n",
        "\n",
        "When you set $\\lambda_{\\verb|GAE|}=1.0$, then $\\hat{A}_t^{\\verb|GAE|}$ is just a diffrence of values without generalization as follows. (See [original paper](https://arxiv.org/pdf/1506.02438) for details.)\n",
        "\n",
        "$\\displaystyle \\sum_{l=0}^{k - 1} \\gamma^l \\delta_{t+l}^V = -V(s_t) + r_t + \\gamma r_{t+1} + \\cdots + \\gamma^{k-1} r_{t+k-1} + \\gamma^k V(s_{t+k}) $\n",
        "\n",
        "It's worth noting that the rewards are never used in GAIL algorithm (because it's imitation learning !), but **here we use episode's reward (reward result) to evaluate how the agent is learned** in this example. (You won't use reward in practical GAIL algorithm, but here I use only for checking how well it's working.)\n",
        "\n",
        "> Note : As I have mentioned above, the truncation in environment is not performed in the environemnt. Instead, this function handles the truncation as follows."
      ],
      "id": "qjVmrJtJ8ncJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ZcPSxad8ncJ"
      },
      "outputs": [],
      "source": [
        "MAX_TIMESTEP = 200\n",
        "\n",
        "gamma = 0.995\n",
        "gae_lambda = 1.0\n",
        "\n",
        "def get_data_by_learner_policy(\n",
        "    env,\n",
        "    policy_net,\n",
        "    value_net,\n",
        "    discriminator_net,\n",
        "    gamma=gamma,\n",
        "    gae_lambda=gae_lambda,\n",
        "    num_samples=num_samples,\n",
        "    batch_size=128,\n",
        "):\n",
        "    \"\"\"\n",
        "    Collect samples with policy pi.\n",
        "    To speed up training, this function runs as a batch.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    env : GridWorld\n",
        "        Environment class.\n",
        "    policy_net : torch.nn.Module\n",
        "        Policy network to pick up action.\n",
        "    value_net : torch.nn.Module\n",
        "        Value network used to get values and advantages.\n",
        "    discriminator_net : torch.nn.Module\n",
        "        Discriminator network used to get values and advantages\n",
        "    gamma : float\n",
        "        A discount value.\n",
        "    gae_lambda : float\n",
        "        A parameter controlling bias and variance in GAE. (See above)\n",
        "    num_samples : int\n",
        "        Number of samples to pick up.\n",
        "    batch_size : int\n",
        "        Batch size used to pick up samples.\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    states : torch.tensor((num_samples), dtype=int)\n",
        "        Collected states.\n",
        "    actions : torch.tensor((num_samples), dtype=int)\n",
        "        Collected actions.\n",
        "    action_logits : torch.tensor((num_samples, ACTION_SIZE), dtype=float)\n",
        "        Logits used to pick up actions.\n",
        "    advantages : torch.tensor((num_samples), dtype=float)\n",
        "        Advantages which is used to optimize policy.\n",
        "        This advantage is obtained by GAE (generalized advantage estimation).\n",
        "        This tensor has graph to be optimized (i.e, can be used for optimization.)\n",
        "    discount : torch.tensor((num_samples), dtype=float)\n",
        "        Discount factor gamma^t.\n",
        "        Later this coefficient is used to get gamma-discounted causal entropy.\n",
        "    average_reward : torch.tensor(float)\n",
        "        The average of episode's reward in all executed episodes.\n",
        "        This reward is not used in GAIL algorithm,\n",
        "        but it's used for the evaluation of training in this example.\n",
        "    \"\"\"\n",
        "\n",
        "    ##########\n",
        "    # Operations are processed as a batch.\n",
        "    # All working tensor has dimension: (step_count, batch_size, ...)\n",
        "    ##########\n",
        "\n",
        "    # initialize results\n",
        "    states = torch.empty((0), dtype=int).to(device)\n",
        "    actions = torch.empty((0), dtype=int).to(device)\n",
        "    action_logits = torch.empty((0, ACTION_SIZE), dtype=float).to(device)\n",
        "    advantages = torch.empty((0), dtype=float).to(device)\n",
        "    discount = torch.empty((0), dtype=float).to(device)\n",
        "\n",
        "    # note : reward is not used in GAIL, but it's used to evaluate how well it's learned...\n",
        "    episode_rewards = torch.empty((0)).to(device)\n",
        "\n",
        "    s = torch.empty((0)).to(device)\n",
        "    while len(states) < num_samples:\n",
        "        #\n",
        "        # initialize episode\n",
        "        #\n",
        "        if s.nelement() == 0:\n",
        "            reward_total = torch.zeros(batch_size).to(device)\n",
        "            s = env.reset(batch_size)\n",
        "            states_ep = torch.empty((0, batch_size), dtype=int).to(device)\n",
        "            actions_ep = torch.empty((0, batch_size), dtype=int).to(device)\n",
        "            action_logits_ep = torch.empty((0, batch_size, ACTION_SIZE), dtype=float).to(device)\n",
        "\n",
        "        #\n",
        "        # step episode\n",
        "        #\n",
        "\n",
        "        # get state\n",
        "        states_ep = torch.cat((states_ep, s.unsqueeze(dim=0)), dim=0)\n",
        "        # get action with policy pi\n",
        "        s_onehot = F.one_hot(s, num_classes=STATE_SIZE)\n",
        "        logits = policy_net(s_onehot.float()).detach()\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        a = torch.multinomial(probs, num_samples=1).squeeze(dim=-1)\n",
        "        actions_ep = torch.cat((actions_ep, a.unsqueeze(dim=0)), dim=0)\n",
        "        action_logits_ep = torch.cat((action_logits_ep, logits.unsqueeze(dim=0)), dim=0)\n",
        "        # step to the next state\n",
        "        s, r, done = env.step(a, s)\n",
        "        # (note : reward is only used to evaluate)\n",
        "        reward_total += r\n",
        "\n",
        "        #\n",
        "        # finalize episode\n",
        "        #\n",
        "\n",
        "        # pick up indices to be done (not truncated) and add to reward's record\n",
        "        done_indices = done.nonzero().squeeze(dim=-1)\n",
        "        if env.step_count==MAX_TIMESTEP:\n",
        "            episode_rewards = torch.cat((episode_rewards, reward_total))\n",
        "        elif len(done_indices) > 0:\n",
        "            episode_rewards = torch.cat((episode_rewards, reward_total[done_indices]))\n",
        "        # pick up indices to be finalized (terminated or truncated)\n",
        "        trunc = torch.tensor((env.step_count==MAX_TIMESTEP) or (env.step_count >= num_samples - len(states))).to(device)\n",
        "        fin = torch.logical_or(done, trunc)\n",
        "        fin_indices = fin.nonzero().squeeze(dim=-1)\n",
        "        if len(fin_indices) > 0:\n",
        "            fin_len = len(fin_indices)\n",
        "            # pick up results to be finalized\n",
        "            states_fin = states_ep[:,fin_indices]\n",
        "            actions_fin = actions_ep[:,fin_indices]\n",
        "            action_logits_fin = action_logits_ep[:,fin_indices,:]\n",
        "            # get log(D(s,a))\n",
        "            states_onehot_fin = F.one_hot(states_fin, num_classes=STATE_SIZE).float()\n",
        "            actions_onehot_fin = F.one_hot(actions_fin, num_classes=ACTION_SIZE).float()\n",
        "            state_action_fin = torch.cat((states_onehot_fin, actions_onehot_fin), dim=-1)\n",
        "            d_log_fin = torch.log(discriminator_net(state_action_fin).detach().squeeze(dim=-1)) # detach() - gradient update in discriminator is not required\n",
        "            # get values and value loss (see above for TD)\n",
        "            values_current_fin = value_net(states_onehot_fin).squeeze(dim=-1)\n",
        "            # when it's truncated, set next value in last element. 0 otherwise.\n",
        "            if trunc:\n",
        "                state_last = s[fin_indices]\n",
        "                state_last_onehot = F.one_hot(state_last, num_classes=STATE_SIZE).float()\n",
        "                value_last = value_net(state_last_onehot).squeeze(dim=-1)\n",
        "                value_last = value_last.masked_fill(mask=done[fin_indices], value=0.0)\n",
        "            else:\n",
        "                value_last = torch.zeros(fin_len).to(device)\n",
        "            values_next_fin = torch.cat((values_current_fin[1:,:], value_last.unsqueeze(dim=0)), dim=0)\n",
        "            # get delta\n",
        "            delta_fin = d_log_fin + values_next_fin * gamma - values_current_fin\n",
        "            # get advantages (see above for GAE)\n",
        "            gae_params = torch.tensor([(gamma * gae_lambda)**i for i in range(env.step_count)]).to(device)\n",
        "            gae_params = gae_params.unsqueeze(dim=-1).expand(-1, fin_len)\n",
        "            advs_fin = [torch.sum(gae_params[:env.step_count - i,:] * delta_fin[i:,:], dim=0) for i in range(env.step_count)]\n",
        "            advs_fin = torch.stack(advs_fin)\n",
        "            # get gamma-discount\n",
        "            discount_fin = torch.tensor([gamma**i for i in range(env.step_count)]).to(device)\n",
        "            discount_fin = discount_fin.unsqueeze(dim=-1).expand(-1, fin_len)\n",
        "            # add to results\n",
        "            states = torch.cat((states, states_fin.transpose(0,1).flatten()))\n",
        "            actions = torch.cat((actions, actions_fin.transpose(0,1).flatten()))\n",
        "            action_logits = torch.cat((action_logits, action_logits_fin.transpose(0,1).flatten(start_dim=0,end_dim=1)))\n",
        "            advantages = torch.cat((advantages, advs_fin.transpose(0,1).flatten()))\n",
        "            discount = torch.cat((discount, discount_fin.transpose(0,1).flatten()))\n",
        "            # remove finalized items in batch\n",
        "            work_indices = (fin==False).nonzero().squeeze(dim=-1)\n",
        "            states_ep = states_ep[:,work_indices]\n",
        "            actions_ep = actions_ep[:,work_indices]\n",
        "            action_logits_ep = action_logits_ep[:,work_indices,:]\n",
        "            s = s[work_indices]\n",
        "            reward_total = reward_total[work_indices]\n",
        "\n",
        "    # truncate results\n",
        "    states = states[:num_samples]\n",
        "    actions = actions[:num_samples]\n",
        "    action_logits = action_logits[:num_samples,:]\n",
        "    advantages = advantages[:num_samples]\n",
        "    discount = discount[:num_samples]\n",
        "    # shuffle results\n",
        "    rnd_indices = torch.randperm(num_samples)\n",
        "    states = states[rnd_indices]\n",
        "    actions = actions[rnd_indices]\n",
        "    action_logits = action_logits[rnd_indices,:]\n",
        "    advantages = advantages[rnd_indices]\n",
        "    discount = discount[rnd_indices]\n",
        "\n",
        "    return states, actions, action_logits, advantages, discount, torch.mean(episode_rewards)"
      ],
      "id": "7ZcPSxad8ncJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pPOpiha8ncL"
      },
      "source": [
        "### 4. Create a function to get loss for updating $D_w$ (discriminator network)"
      ],
      "id": "8pPOpiha8ncL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO5VpF5F8ncL"
      },
      "source": [
        "Now I build a function to get loss for updating $D_w$ by maximizing $\\mathbb{E}_{\\pi} [\\log(D(s, a))] + \\mathbb{E}_{\\pi_E} [\\log(1 - D(s, a))]$.<br>\n",
        "Maximizing above equation is equivalent to minimizing the following equation. Each term can then be obtained by binary cross entropy (BCE) loss.\n",
        "\n",
        "$\\displaystyle \\verb|discriminator_loss| \\coloneqq (-\\mathbb{E}_{\\pi} [\\log(D(s, a))]) + (-\\mathbb{E}_{\\pi_E} [\\log(1 - D(s, a))])$"
      ],
      "id": "aO5VpF5F8ncL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CP7UMth8ncL"
      },
      "outputs": [],
      "source": [
        "def get_discriminator_loss(discriminator_net, exp_states, exp_actions, pi_states, pi_actions):\n",
        "    \"\"\"\n",
        "    Collect samples with policy pi.\n",
        "    To speed up training, this function runs as batch.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    discriminator_net : torch.nn.Module\n",
        "        Discriminator network to be updated\n",
        "    exp_states : torch.tensor((num_samples), dtype=int)\n",
        "        States visited by expert policy.\n",
        "    exp_actions : torch.tensor((num_samples), dtype=int)\n",
        "        Corresponding actions to be taken by expert.\n",
        "    pi_states : torch.tensor((num_samples), dtype=int)\n",
        "        States visited by policy pi.\n",
        "    pi_actions : torch.tensor((num_samples), dtype=int)\n",
        "        Corresponding actions to be taken by policy pi.\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    Mean of discriminator loss\n",
        "    \"\"\"\n",
        "\n",
        "    # get D(s,a)\n",
        "    states_onehot_pi = F.one_hot(pi_states, num_classes=STATE_SIZE).float()\n",
        "    actions_onehot_pi = F.one_hot(pi_actions, num_classes=ACTION_SIZE).float()\n",
        "    state_action_pi = torch.cat((states_onehot_pi, actions_onehot_pi), dim=-1)\n",
        "    d_pi = discriminator_net(state_action_pi).squeeze(dim=-1)\n",
        "\n",
        "    states_onehot_exp = F.one_hot(exp_states, num_classes=STATE_SIZE).float()\n",
        "    actions_onehot_exp = F.one_hot(exp_actions, num_classes=ACTION_SIZE).float()\n",
        "    state_action_exp = torch.cat((states_onehot_exp, actions_onehot_exp), dim=-1)\n",
        "    d_exp = discriminator_net(state_action_exp).squeeze(dim=-1)\n",
        "\n",
        "    # get mean of binary cross entropy (BCE) loss\n",
        "    mean_loss_pi = F.binary_cross_entropy(d_pi, torch.ones_like(d_pi).to(device))\n",
        "    mean_loss_exp = F.binary_cross_entropy(d_exp, torch.zeros_like(d_exp).to(device))\n",
        "\n",
        "    return mean_loss_pi + mean_loss_exp"
      ],
      "id": "_CP7UMth8ncL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gjtve3AA8ncM"
      },
      "source": [
        "### 5. Create a function to get loss for updating $\\pi_{\\theta}$ (policy network)"
      ],
      "id": "Gjtve3AA8ncM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJjL1wAe8ncO"
      },
      "source": [
        "Now we create a function to get loss for updating $\\theta$ to minimize $\\mathbb{E}_{\\pi} [\\log(D(s, a))] - \\lambda H(\\pi) $ (using the updated discriminator $D(s,a)$) with reinforcement learning algorithms.\n",
        "\n",
        "In [original paper](https://arxiv.org/pdf/1606.03476), TRPO (trust region policy optimization) is used to update policy parameters $\\theta$, but here **I instead use PPO** with entropy regularizer (see [here](https://github.com/tsmatz/reinforcement-learning-tutorials/blob/master/04-ppo.ipynb)) to update $\\theta$, because PPO is easier to implement.<br>\n",
        "I note that both TRPO and PPO are motivated by the same objective to avoid stepping so far (by using KL-divergence) in optimizing policy.\n",
        "\n",
        "> Note : In practical TRPO (to solve problems analytically), it needs approximation by Taylor expansion and Lagrangians.\n",
        "\n",
        "Now let's briefly summarize PPO algorithm.\n",
        "\n",
        "As I have discussed in [here](https://github.com/tsmatz/reinforcement-learning-tutorials/blob/master/04-ppo.ipynb), PPO algorithm optimizes $\\theta$ to minimize advantage loss, KL (KL-divergence) loss, value loss, and also entropy loss $- \\lambda H(\\pi)$. (Here $\\lambda$ is a weight's coefficient for entropy loss.)\n",
        "\n",
        "As I have discussed in [here](https://github.com/tsmatz/reinforcement-learning-tutorials/blob/master/04-ppo.ipynb), the advantage loss is obtained by the following equation (see below note) :\n",
        "\n",
        "$\\displaystyle \\mathbb{E}_{\\pi} \\left[ \\frac{P(a | \\pi_\\theta (s))}{P(a | \\pi_{\\theta_{old}} (s))} A \\right]$\n",
        "\n",
        "where $A$ is the advantage obtained by the value $\\log(D(s, a))$.\n",
        "\n",
        "> Note : In regular RL, $\\mathbb{E}(R)$ (where $R$ is reward) is maximized in optimization, but here $\\mathbb{E}(\\log(D(s,a)))$ should be minimized, because $\\log(D(s,a))$ is a loss score (which value is always negative) and $\\log(D(s,a))$ is getting lower (i.e, $D(s,a)$ is closer to 0) when it’s optimized.<br>\n",
        "> Then advantages in PPO should also be minimized (not maximized) in policy optimization in GAIL algorithm.\n",
        "\n",
        "The entropy $ H $ is $\\gamma$-discounted causal entropy as follows. (See [MCE IRL example](./04_mce_irl.ipynb).) :\n",
        "\n",
        "$\\displaystyle H(\\pi) \\coloneqq \\mathbb{E}_{\\pi} \\left[ -\\sum_t \\gamma^t \\log \\pi_t(a_t|s_t) \\right] $\n",
        "\n",
        "For value loss, I'll simply use the mean square loss (MSE) of advantages in this example. (See above description for GAE with $\\lambda_{\\verb|GAE|}=1.0$.)<br>\n",
        "Unlike advantages itself, value loss is always positive.\n",
        "\n",
        "> Note : Log probability is equivalent to the negative value of cross-entropy error in categorical distribution. I have then used ```-torch.nn.functional.cross_entropy()``` to get log probability.\n",
        "\n",
        "> Note : In PPO, advantage can also be normalized as $(A-\\mu) / \\sigma$, where $\\mu$ is a mean and $\\sigma$ is a standard deviation of advantages.<br>\n",
        "> In this training, I haven't used normalized advantage."
      ],
      "id": "iJjL1wAe8ncO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSp4wFR68ncP"
      },
      "outputs": [],
      "source": [
        "def get_policy_loss(policy_net, states, actions, logits, advantages, discount):\n",
        "    logits_old = logits\n",
        "\n",
        "    # get logits to be used for optimization\n",
        "    s_onehot = F.one_hot(states, num_classes=STATE_SIZE)\n",
        "    logits_new = policy_net(s_onehot.float())\n",
        "\n",
        "    # get advantage loss (see above)\n",
        "    logprb_old = -F.cross_entropy(logits_old, actions, reduction=\"none\") # get log probability (see above note)\n",
        "    logprb_new = -F.cross_entropy(logits_new, actions, reduction=\"none\") # get log probability (see above note)\n",
        "    prb_ratio = torch.exp(logprb_new - logprb_old) # P(a|pi_new(s)) / P(a|pi_old(s))\n",
        "    advantage_loss = prb_ratio * advantages\n",
        "\n",
        "    # get value loss (see above)\n",
        "    value_loss = torch.mean(advantages**2)\n",
        "\n",
        "    # get KL loss\n",
        "    # (see https://github.com/tsmatz/reinforcement-learning-tutorials/blob/master/04-ppo.ipynb)\n",
        "    l_old = logits_old - torch.amax(logits_old, dim=1, keepdim=True) # reduce quantity\n",
        "    l_new = logits_new - torch.amax(logits_new, dim=1, keepdim=True) # reduce quantity\n",
        "    e_old = torch.exp(l_old)\n",
        "    e_new = torch.exp(l_new)\n",
        "    e_sum_old = torch.sum(e_old, dim=1, keepdim=True)\n",
        "    e_sum_new = torch.sum(e_new, dim=1, keepdim=True)\n",
        "    p_old = e_old / e_sum_old\n",
        "    kl_loss = torch.sum(\n",
        "        p_old * (l_old - torch.log(e_sum_old) - l_new + torch.log(e_sum_new)),\n",
        "        dim=1,\n",
        "        keepdim=True)\n",
        "\n",
        "    # get gamma-discounted causal entropy loss (see above)\n",
        "    entropy_loss = -discount * logprb_new\n",
        "\n",
        "    return advantage_loss, value_loss, kl_loss, entropy_loss"
      ],
      "id": "OSp4wFR68ncP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKPUxd798ncQ"
      },
      "source": [
        "### 6. Put it all together (Train and optimize parameter)"
      ],
      "id": "KKPUxd798ncQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ft5awI48ncQ"
      },
      "source": [
        "Now we alternately update $w$ (discriminator network) and $\\theta$ (policy network).\n",
        "\n",
        "In this game, the maximum episode's reward without losing any rewards is ```10.0```, and I have then trained the agent until the estimated reward is over ```5.0```. (See [Readme.md](https://github.com/tsmatz/imitation-learning-tutorials/blob/master/Readme.md) for game rule in this environment.)\n",
        "\n",
        "> Note : The reward is not used in optimization, and it's used only for evaluation. (The reward cannot be used in practices.)"
      ],
      "id": "4Ft5awI48ncQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bshwlA-F8ncR",
        "outputId": "e19effff-8bcd-402d-93e5-a220ec0e9572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter0 - reward mean -66.8984\n",
            "iter200 - reward mean -66.7211\n",
            "iter400 - reward mean -24.2926\n",
            "iter600 - reward mean -5.2324\n",
            "iter800 - reward mean -1.4758\n",
            "iter1000 - reward mean 0.3354\n",
            "iter1200 - reward mean 1.3792\n",
            "iter1400 - reward mean 2.0224\n",
            "iter1600 - reward mean 2.4058\n",
            "iter1800 - reward mean 2.9117\n",
            "iter2000 - reward mean 2.9053\n",
            "iter2200 - reward mean 3.3491\n",
            "iter2400 - reward mean 3.5652\n",
            "iter2600 - reward mean 3.8741\n",
            "iter2800 - reward mean 3.9068\n",
            "iter3000 - reward mean 4.0853\n",
            "iter3200 - reward mean 4.2966\n",
            "iter3400 - reward mean 4.4805\n",
            "iter3600 - reward mean 4.7280\n",
            "iter3800 - reward mean 4.6663\n",
            "iter3814 - reward mean 5.2295\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "vf_coeff = 0.01\n",
        "kl_coeff = 1.0\n",
        "_lambda = 0.005\n",
        "\n",
        "reward_records = []\n",
        "\n",
        "opt_d = torch.optim.AdamW(discriminator.parameters(), lr=0.001)\n",
        "opt_pi = torch.optim.AdamW(list(policy_func.parameters()) + list(value_func.parameters()), lr=0.001)\n",
        "\n",
        "for iter_num in range(10000):\n",
        "    # get expert data\n",
        "    states_ex, actions_ex = get_data_by_expert()\n",
        "\n",
        "    # get data by policy pi\n",
        "    states, actions, logits, advantages, discount, reward_mean = get_data_by_learner_policy(\n",
        "        env=env,\n",
        "        policy_net=policy_func,\n",
        "        value_net=value_func,\n",
        "        discriminator_net=discriminator,\n",
        "    )\n",
        "    reward_records.append(reward_mean.item())\n",
        "\n",
        "    # update discriminator\n",
        "    d_loss = get_discriminator_loss(\n",
        "        discriminator,\n",
        "        states_ex,\n",
        "        actions_ex,\n",
        "        states,\n",
        "        actions,\n",
        "    )\n",
        "    opt_d.zero_grad()\n",
        "    d_loss.backward()\n",
        "    opt_d.step()\n",
        "\n",
        "    # update policy\n",
        "    adv_loss, val_loss, kl_loss, ent_loss = get_policy_loss(\n",
        "        policy_func,\n",
        "        states,\n",
        "        actions,\n",
        "        logits,\n",
        "        advantages,\n",
        "        discount,\n",
        "    )\n",
        "    pi_loss = adv_loss + val_loss * vf_coeff + kl_loss * kl_coeff + ent_loss * _lambda\n",
        "    opt_pi.zero_grad()\n",
        "    pi_loss.sum().backward()\n",
        "    opt_pi.step()\n",
        "\n",
        "    # output log\n",
        "    if iter_num % 200 == 0:\n",
        "        line_end = \"\\n\"\n",
        "        print_reward = np.average(reward_records[-200:])\n",
        "    else:\n",
        "        line_end = \"\\r\"\n",
        "        print_reward = reward_records[-1]\n",
        "    print(\"iter{} - reward mean {:2.4f}\".format(iter_num, print_reward), end=line_end)\n",
        "\n",
        "    # stop if reward mean reaches to threshold\n",
        "    if np.average(reward_records[-20:]) > 5.0:\n",
        "        break\n",
        "\n",
        "print(\"\\nDone\")"
      ],
      "id": "bshwlA-F8ncR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYc2BwTL8ncR"
      },
      "source": [
        "I plot results of evaluated episode reward till 1000 iterations.<br>\n",
        "As you can see below, the agent is well-trained and optimized."
      ],
      "id": "kYc2BwTL8ncR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zcs1ZPDF8ncR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "outputId": "2f91312e-f7a7-460d-cd35-7ea8536f3bc7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7a17465ccc20>]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plot_records = reward_records[:1000]\n",
        "plt.plot(plot_records)"
      ],
      "id": "Zcs1ZPDF8ncR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZ_taXkE8ncS"
      },
      "source": [
        "The following is the plotting of all evaluated results in the training."
      ],
      "id": "gZ_taXkE8ncS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDfPfDVK8ncS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbba2907-a6f7-4e9a-8a1f-06858f7f13ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7a17465c3620>]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(reward_records)"
      ],
      "id": "UDfPfDVK8ncS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYf5yZPS8ncT"
      },
      "outputs": [],
      "source": [],
      "id": "GYf5yZPS8ncT"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}