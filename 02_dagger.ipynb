{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7cae5cc-fd75-40a1-80b2-bd48c6e69013",
   "metadata": {},
   "source": [
    "# DAgger (Dataset Aggregation)\n",
    "\n",
    "In Behavioral Cloning (BC), we have seen the method to learn expert's behavior with a manner of solving regression/classification problems.\n",
    "\n",
    "However, it sometimes happens that the learner encounters unknown states that the expert never encounters in her/his successful demonstrations. A small error at early time-step may then lead to further mistakes, leading to poor performance.<br>\n",
    "DAgger addresses this problem by collecting the additional dataset of trajectories under the state distribution induced by the learned policy.\n",
    "\n",
    "Unlike previous behavior cloning (BC) example, DAgger queries an expert **online** for demonstrations.<br>\n",
    "This eventually reduces the size of training demonstrations to obtain satisfactory performance (compared to vanilla behavior cloning), but it's limited to the case in which the trainer can query an expert online (interactively) for demonstrations.\n",
    "\n",
    "I note that DAgger essentially differs from the incremental learning, in which RL method follows to refine the trained policy. Unlike reinforcement learning (RL), DAgger doesn't also use the rewards to refine the policy.\n",
    "\n",
    "> Note : However, you can progressively combine behavior cloning (BC), data aggregation (DAgger), and reinforcement learning (RL) for refinement to improve performance.<br>\n",
    "> See [here](https://developer.nvidia.com/blog/training-sim-to-real-transferable-robotic-assembly-skills-over-diverse-geometries/) for real Robotics example in NVIDIA.\n",
    "\n",
    "Now let's start.\n",
    "\n",
    "*(back to [index](https://github.com/tsmatz/imitation-learning-tutorials/))*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715f1e95-d88f-4a41-bd0f-9f5b6885cacf",
   "metadata": {},
   "source": [
    "Before we start, we need to install the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35dde25-4a6e-4eb1-8fd3-9dc34cb81b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch numpy matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9beeb14-fa75-4f68-9b50-bd38633ecf83",
   "metadata": {},
   "source": [
    "## Restore environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2413be-f2bd-4a69-befe-73179832b739",
   "metadata": {},
   "source": [
    "Firstly, I restore GridWorld environment from JSON file.\n",
    "\n",
    "For details about this environment, see [Readme.md](https://github.com/tsmatz/imitation-learning-tutorials/blob/master/Readme.md).\n",
    "\n",
    "> Note : See [this script](./00_generate_expert_trajectories.ipynb) for generating the same environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5243b603-c3e9-4bbe-85d5-37d4101fae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "GRID_SIZE = 50\n",
    "MAX_TIMESTEP = 200\n",
    "\n",
    "class GridWorld:\n",
    "    \"\"\"\n",
    "    This environment is motivated by the following paper.\n",
    "    https://proceedings.mlr.press/v15/boularias11a/boularias11a.pdf\n",
    "\n",
    "    - It has 50 x 50 grids (cells).\n",
    "    - The agent has four actions for moving in one of the directions of the compass.\n",
    "    - If ```transition_prob``` = True, the actions succeed with probability 0.7,\n",
    "      a failure results in a uniform random transition to one of the adjacent states.\n",
    "    - A reward of 10 is given for reaching the goal state, located on the bottom-right corner.\n",
    "    - For the remaining states,\n",
    "      the reward function was randomly set to 0 with probability 2/3\n",
    "      and to âˆ’1 with probability 1/3.\n",
    "    - If the agent moves across the border, it's given the fail reward (i.e, reward=`-1`).\n",
    "    - The initial state is sampled from a uniform distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, reward_map, valid_states, transition_prob=True):\n",
    "        \"\"\"\n",
    "        Initialize class.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        reward_map : float[GRID_SIZE * GRID_SIZE]\n",
    "            Reward for each state.\n",
    "        valid_states : list(int[2])\n",
    "            List of states, in which the agent can reach to goal state without losing any rewards.\n",
    "            Each state is a 2d vector, [row, column].\n",
    "            When you call reset(), the initial state is picked up from these states.\n",
    "        transition_prob : bool\n",
    "            True if transition probability (above) is enabled.\n",
    "            False when we generate an expert agent without noise.\n",
    "        \"\"\"\n",
    "        self.reward_map = np.array(reward_map)\n",
    "        self.valid_states = np.array(valid_states)\n",
    "        self.transition_prob = transition_prob\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Randomly, get initial state (single state) from valid states.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        state : int\n",
    "            Return the picked-up state id.\n",
    "        \"\"\"\n",
    "        # initialize step count\n",
    "        self.step_count = 0\n",
    "        # pick up sample of valid states\n",
    "        state_2d = random.choice(self.valid_states)\n",
    "        # convert 2d index to 1d index\n",
    "        state_1d = state_2d[0] * GRID_SIZE + state_2d[1]\n",
    "        # return result\n",
    "        return state_1d\n",
    "\n",
    "    def step(self, action, state):\n",
    "        \"\"\"\n",
    "        Take action, proceed step, and return the result.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        action : int\n",
    "            Actions to take\n",
    "            (0=UP 1=DOWN 2=LEFT 3=RIGHT)\n",
    "        state : int\n",
    "            Current state id.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        new-state : int\n",
    "            New state id.\n",
    "        reward : int\n",
    "            The obtained reward.\n",
    "        done : bool\n",
    "            Flag to check whether it terminates.\n",
    "        \"\"\"\n",
    "        # if transition prob is enabled, apply transition\n",
    "        if self.transition_prob:\n",
    "            # the action succeeds with probability 0.7\n",
    "            prob = [.1]*4\n",
    "            prob[action] *= 7.0\n",
    "            action_onehot = np.random.multinomial(1, prob)\n",
    "        else:\n",
    "            action_onehot = np.zeros(4, dtype=int)\n",
    "            action_onehot[action] += 1\n",
    "        # get 2d state\n",
    "        mod, reminder = divmod(state, GRID_SIZE)\n",
    "        state_2d = np.array([mod, reminder])\n",
    "        # move state\n",
    "        # (0=UP 1=DOWN 2=LEFT 3=RIGHT)\n",
    "        up_and_down = action_onehot[1] - action_onehot[0]\n",
    "        left_and_right = action_onehot[3] - action_onehot[2]\n",
    "        new_state = state_2d + np.array([up_and_down, left_and_right])\n",
    "        # set reward\n",
    "        reward = 0.0\n",
    "        if (new_state[0] < 0) or (new_state[0] >= GRID_SIZE) or (new_state[1] < 0) or (new_state[1] >= GRID_SIZE):\n",
    "            # if location is out of border, set reward=-1\n",
    "            reward -= 1.0\n",
    "        else:\n",
    "            # if succeed, add reward of current state\n",
    "            state_1d = new_state[0] * GRID_SIZE + new_state[1]\n",
    "            reward += self.reward_map[state_1d]\n",
    "        # correct location\n",
    "        new_state = np.clip(new_state, 0, GRID_SIZE-1)\n",
    "        # return result\n",
    "        self.step_count += 1\n",
    "        return new_state[0] * GRID_SIZE + new_state[1], reward, (new_state[0]==GRID_SIZE-1 and new_state[1]==GRID_SIZE-1) or (self.step_count==MAX_TIMESTEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86cb09b4-9b41-4a1c-8a3e-b9a6f73d8252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"gridworld.json\", \"r\") as f:\n",
    "    json_object = json.load(f)\n",
    "    env = GridWorld(**json_object, transition_prob=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8892d179-c4a7-4274-b682-dddd8349182f",
   "metadata": {},
   "source": [
    "## Define policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605ebd18-e547-464a-8977-819f298b0259",
   "metadata": {},
   "source": [
    "Now I build a policy $\\pi$.\n",
    "\n",
    "In DAgger, we need both expert policy and learner policy.<br>\n",
    "The expert policy is already generated in [this script](./00_generate_expert_trajectories.ipynb) and the trained parameters are saved as ```expert_actor.pt``` in this repository.\n",
    "\n",
    "This network receives the current state (one-hot state) as input and returns the optimal action (action's logits) as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5d9fdbd-a62d-4768-aec5-39c75cc29dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Recover policy for expert\n",
    "# (See 00_generate_expert_trajectories.ipynb.)\n",
    "class ExpertNet(nn.Module):\n",
    "    def __init__(self, hidden_dim=16):\n",
    "        super().__init__()\n",
    "        self.output = nn.Linear(GRID_SIZE*GRID_SIZE, 4, bias=False)\n",
    "\n",
    "    def forward(self, state):\n",
    "        logits = self.output(state)\n",
    "        return logits\n",
    "\n",
    "# Define policy for learner\n",
    "class LearnerNet(nn.Module):\n",
    "    def __init__(self, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(GRID_SIZE*GRID_SIZE, hidden_dim)\n",
    "        self.classify = nn.Linear(hidden_dim, 4)\n",
    "\n",
    "    def forward(self, s):\n",
    "        outs = self.hidden(s)\n",
    "        outs = F.relu(outs)\n",
    "        logits = self.classify(outs)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9fe58c8-2d6d-4577-be22-2a2a0e48faf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load expert model and freeze\n",
    "expert_func = ExpertNet().to(device)\n",
    "expert_func.load_state_dict(torch.load(\"expert_actor.pt\"))\n",
    "for param in expert_func.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# load learner model\n",
    "learner_func = LearnerNet().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af6b909-fb3a-4c7b-be57-9e9d2cdff393",
   "metadata": {},
   "source": [
    "## Run agent before training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8bc5a6-b58c-49b2-9975-d6645e2afa5b",
   "metadata": {},
   "source": [
    "For comparison, now I run this agent without any training.\n",
    "\n",
    "In this game, the maximum episode's reward without losing any rewards is ```10.0```.<br>\n",
    "As you can see below, it has low average of rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "418d8cdc-cb9b-4f2a-836a-e038e561b32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature vector (which shape is (GRID_SIZE*GRID_SIZE,)) of state to feed model\n",
    "def get_feature(state):\n",
    "    \"\"\"\n",
    "    Return one-hot feature array from state id.\n",
    "    e.g, 3 --> [0, 0, 0, 1, 0, ... ]\n",
    "    \"\"\"\n",
    "    # get one-hot array --> size (batch_size, GRID_SIZE * GRID_SIZE)\n",
    "    return F.one_hot(torch.tensor(state).to(device), num_classes=GRID_SIZE*GRID_SIZE)\n",
    "\n",
    "# Pick stochastic samples with policy model\n",
    "def pick_sample(policy, s):\n",
    "    \"\"\"\n",
    "    Stochastically pick up action and logits with policy model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    policy : torch.nn.Module\n",
    "        Policy network to use\n",
    "    s : tensor of int[GRID_SIZE*GRID_SIZE])\n",
    "        The feature (one-hot) of state.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    action : tensor of int\n",
    "        The picked-up actions.\n",
    "    \"\"\"\n",
    "    # Get logits from state\n",
    "    # --> size : (4,)\n",
    "    inputs = s.unsqueeze(dim=0)\n",
    "    logits = policy(inputs.float())\n",
    "    logits = logits.squeeze(dim=0)\n",
    "    # From logits to probabilities\n",
    "    # --> size : (4,)\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    # Pick up action's sample\n",
    "    # --> size : (1,)\n",
    "    a = torch.multinomial(probs, num_samples=1)\n",
    "    # --> size : ()\n",
    "    a = a.squeeze()\n",
    "\n",
    "    # Return\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e57b8b92-2df9-4b44-b4ce-14b123cc7e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed  300 /  300 episodes ...\n",
      "Done\n",
      "Average reward is -68.39333333333333.\n"
     ]
    }
   ],
   "source": [
    "def evaluate_policy(policy, eval_num, verbose=False):\n",
    "    score_list = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(eval_num):\n",
    "            score = 0\n",
    "            done = False\n",
    "            s = env.reset()\n",
    "            while not done:\n",
    "                s_onehot = get_feature(s)\n",
    "                a = pick_sample(policy, s_onehot)\n",
    "                s, r, done = env.step(a, s)\n",
    "                score += r\n",
    "            score_list.append(score)\n",
    "            if verbose:\n",
    "                print(\"Processed {:4d} / {:4d} episodes ...\".format(i + 1, eval_num), end=\"\\r\")\n",
    "    if verbose:\n",
    "        print(\"\\nDone\")\n",
    "    return sum(score_list) / len(score_list)\n",
    "\n",
    "avg = evaluate_policy(learner_func, 300, verbose=True)\n",
    "print(\"Average reward is {}.\".format(avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a25364e-c584-47cb-b090-dc97febf3863",
   "metadata": {},
   "source": [
    "## Train policy with DAgger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff25e4b-aaec-40e5-81a9-7737a1501004",
   "metadata": {},
   "source": [
    "In DAgger, the following stochastic mixing $\\pi_i$ (where $i$ is the number of training iteration) between expert policy $\\pi^*$ and learner policy $\\hat{\\pi}_i$ is used to collect the visited states. (See [original paper](https://arxiv.org/pdf/1011.0686).)\n",
    "\n",
    "$\\pi_i = \\beta_i \\pi^* + (1 - \\beta_i) \\hat{\\pi}_i$\n",
    "\n",
    "where $\\beta_i$ satisfies $\\frac{1}{N} \\sum_{i=1}^{N} \\beta_i \\to 0$.\n",
    "\n",
    "In this example, I briefly set $\\beta_i = p^{i - 1}$ where $0 \\lt p \\lt 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75d853dd-d2b2-41c8-ab1b-f922253443ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_beta(p, iter_num):\n",
    "    return p**iter_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28619b24-d5b0-402c-9a6f-fe5e5f2a2b85",
   "metadata": {},
   "source": [
    "Now I create a function to collect the visited states by applying the stochastic mixing with $\\beta_i$.\n",
    "\n",
    "> Note : Here I make an agent step one by one, but please proceed as a batch if possible, in order to speed up training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c87fb33-348f-44c6-852f-f6147341fb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def collect_states(expert, learner, p_for_beta, i, collect_dat):\n",
    "    \"\"\"\n",
    "    Collect visited states with mixing policies on i-th iteration\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    expert : torch.nn.Module\n",
    "        Online expert policy.\n",
    "    learner : torch.nn.Module\n",
    "        Learner policy.\n",
    "    p_for_beta : int\n",
    "        Base p value used in get_beta() function.\n",
    "    i : int\n",
    "        The number of training iteration\n",
    "        (which is passed as iter_num in get_beta() function)\n",
    "    collect_dat : int\n",
    "        The number of data to collect.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    states : tensor of int[collect_dat, GRID_SIZE*GRID_SIZE]\n",
    "        Collected onehot states. (The number of row is collect_dat.)\n",
    "    \"\"\"\n",
    "\n",
    "    collected_states = []\n",
    "    beta  = get_beta(p_for_beta, i)\n",
    "    done = True\n",
    "    while len(collected_states) < collect_dat:\n",
    "        if done:\n",
    "            s = env.reset()\n",
    "            done = False\n",
    "        s_onehot = get_feature(s)\n",
    "        collected_states.append(s_onehot)\n",
    "        rnd = random.uniform(0, 1)\n",
    "        policy = expert if rnd < beta else learner\n",
    "        with torch.no_grad():\n",
    "            a = pick_sample(policy, s_onehot)\n",
    "        s, _, done = env.step(a, s)\n",
    "    return torch.stack(collected_states, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31454b5-6c2e-4fb3-8a96-2e25ef3ab3be",
   "metadata": {},
   "source": [
    "Now we start training with DAgger.\n",
    "\n",
    "> Note : To simplify, here I store all history in memory, but in practice, please save on disk to prevent the failure of memory allocation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25168c4b-2f10-490a-90b8-fc2238649d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1 - Evaluation result (Average reward) -66.795\n",
      "Iteration  2 - Evaluation result (Average reward) -62.37\n",
      "Iteration  3 - Evaluation result (Average reward) -53.07\n",
      "Iteration  4 - Evaluation result (Average reward) -40.26\n",
      "Iteration  5 - Evaluation result (Average reward) -34.41\n",
      "Iteration  6 - Evaluation result (Average reward) -28.63\n",
      "Iteration  7 - Evaluation result (Average reward) -20.155\n",
      "Iteration  8 - Evaluation result (Average reward) -13.59\n",
      "Iteration  9 - Evaluation result (Average reward) -7.31\n",
      "Iteration 10 - Evaluation result (Average reward) -3.105\n",
      "Iteration 11 - Evaluation result (Average reward) 0.685\n",
      "Iteration 12 - Evaluation result (Average reward) 2.78\n",
      "Iteration 13 - Evaluation result (Average reward) 4.215\n",
      "Iteration 14 - Evaluation result (Average reward) 5.325\n",
      "Iteration 15 - Evaluation result (Average reward) 4.795\n",
      "Iteration 16 - Evaluation result (Average reward) 6.05\n",
      "Iteration 17 - Evaluation result (Average reward) 6.605\n",
      "Iteration 18 - Evaluation result (Average reward) 6.235\n",
      "Iteration 19 - Evaluation result (Average reward) 7.415\n",
      "Iteration 20 - Evaluation result (Average reward) 7.28\n",
      "Iteration 21 - Evaluation result (Average reward) 7.5\n",
      "Iteration 22 - Evaluation result (Average reward) 7.79\n",
      "Iteration 23 - Evaluation result (Average reward) 7.375\n",
      "Iteration 24 - Evaluation result (Average reward) 8.04\n",
      "Iteration 25 - Evaluation result (Average reward) 7.46\n",
      "Iteration 26 - Evaluation result (Average reward) 8.135\n",
      "Iteration 27 - Evaluation result (Average reward) 7.965\n",
      "Iteration 28 - Evaluation result (Average reward) 8.145\n",
      "Iteration 29 - Evaluation result (Average reward) 8.175\n",
      "Iteration 30 - Evaluation result (Average reward) 8.135\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Define train() function\n",
    "#\n",
    "def train(expert, learner, p_for_beta, collect_dat, total_aggregate, train_batch_size, verbose=False):\n",
    "    \"\"\"\n",
    "    Train with DAgger.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    expert : torch.nn.Module\n",
    "        Online expert policy.\n",
    "    learner : torch.nn.Module\n",
    "        Learner policy.\n",
    "    p_for_beta : int\n",
    "        Base p value used in get_beta() function.\n",
    "    collect_dat : int\n",
    "        The number of data to collect in each data aggregation.\n",
    "    total_aggregate : int\n",
    "        The number of aggregation.\n",
    "        As a result, the number of total collected data will be collect_dat * total_aggregate.\n",
    "    train_batch_size : int\n",
    "        The number of data in each training batch.\n",
    "        The collected data is divided into this chunk as a batch, and each batch is then trained.\n",
    "    verbose : bool\n",
    "        Whether to print results or not\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    logs : int[total_aggregate]\n",
    "        Returns the results of evaluated rewards in each aggregation.\n",
    "    \"\"\"\n",
    "\n",
    "    reward_log = []\n",
    "    visited_states_all = torch.empty((0,GRID_SIZE*GRID_SIZE), dtype=torch.int64).to(device)\n",
    "    expert_actions_all = torch.empty((0), dtype=torch.int64).to(device)\n",
    "\n",
    "    # create optimizer\n",
    "    opt = torch.optim.AdamW(learner.parameters(), lr=0.001)\n",
    "    \n",
    "    for i in range(total_aggregate):\n",
    "        # collect visited states (onehot)\n",
    "        visited_states = collect_states(expert, learner, p_for_beta, i, collect_dat)\n",
    "        # collect expert actions\n",
    "        with torch.no_grad():\n",
    "            logits = expert(visited_states.float())\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        expert_actions = torch.multinomial(probs, num_samples=1)\n",
    "        expert_actions = expert_actions.squeeze(dim=-1)\n",
    "        # combine dataset\n",
    "        visited_states_all = torch.cat((visited_states_all, visited_states), dim=0)\n",
    "        expert_actions_all = torch.cat((expert_actions_all, expert_actions), dim=0)\n",
    "        # shuffle dataset for training\n",
    "        indices = torch.randperm(visited_states_all.shape[0])\n",
    "        visited_states_train = visited_states_all[indices]\n",
    "        expert_actions_train = expert_actions_all[indices]\n",
    "        # train leraner policy by chunking dataset\n",
    "        for j in range(0, collect_dat, train_batch_size):\n",
    "            opt.zero_grad()\n",
    "            logits = learner(visited_states_train[j:j+train_batch_size].float())\n",
    "            loss = F.cross_entropy(logits, expert_actions_train[j:j+train_batch_size], reduction=\"none\")\n",
    "            loss.sum().backward()\n",
    "            opt.step()\n",
    "        # evaluate policy and log\n",
    "        avg = evaluate_policy(learner, 200)\n",
    "        reward_log.append(avg)\n",
    "        if verbose:\n",
    "            print(\"Iteration {:2d} - Evaluation result (Average reward) {}\".format(i + 1, avg))\n",
    "\n",
    "    # return evaluation reward's log\n",
    "    return reward_log\n",
    "\n",
    "#\n",
    "# Run training\n",
    "#\n",
    "dagger_results = train(\n",
    "    expert=expert_func,\n",
    "    learner=learner_func,\n",
    "    p_for_beta=0.3,\n",
    "    collect_dat=5000,\n",
    "    total_aggregate=30,\n",
    "    train_batch_size=200,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b089553-cad3-48cc-a746-1cd53cb98578",
   "metadata": {},
   "source": [
    "## Compare results with BC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22474b14-0fb1-44ca-afa8-5450a3913715",
   "metadata": {},
   "source": [
    "Now let's compare with the results of vanilla BC (behavior cloning).\n",
    "\n",
    "> Note : In below code, I have trained with BC by setting ```p_for_beta=1.0```.\n",
    "\n",
    "As you can easily see, DAgger has better performance (converge faster) than the results of vanilla BC.\n",
    "\n",
    "This example uses a primitive environment (GridWorld) to learn policy, but the real system is more complex and the learner often encounters the unseen states (especillay, in early stages) that the expert never encounters in successful demonstrations. As a result, the learner never converges or very slowly converges into optimal performance in vanilla BC methods.<br>\n",
    "In such case, there might be a clear difference between the results of two methods.\n",
    "\n",
    "DAgger addresses this problem by applying optimization with the visited states induced also by learner policy (not only expert policy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f496130a-09e9-4696-8bb6-6f08e021c40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# train with behavior cloning (BC)\n",
    "# (by setting p_for_beta=1.0)\n",
    "bc_learner_func = LearnerNet().to(device)\n",
    "bc_results = train(\n",
    "    expert=expert_func,\n",
    "    learner=bc_learner_func,\n",
    "    p_for_beta=1.0,\n",
    "    collect_dat=5000,\n",
    "    total_aggregate=30,\n",
    "    train_batch_size=200,\n",
    ")\n",
    "\n",
    "# plot\n",
    "plt.plot(dagger_results, label=\"DAgger\")\n",
    "plt.plot(bc_results, label=\"BC\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0170c629-e047-4933-bdf7-3f2d2e8d44c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-67.285,\n",
       " -65.925,\n",
       " -52.175,\n",
       " -39.655,\n",
       " -31.535,\n",
       " -27.555,\n",
       " -27.33,\n",
       " -21.225,\n",
       " -16.61,\n",
       " -14.44,\n",
       " -10.965,\n",
       " -7.35,\n",
       " -6.5,\n",
       " -4.74,\n",
       " -0.695,\n",
       " -1.635,\n",
       " 1.25,\n",
       " 1.37,\n",
       " 1.925,\n",
       " 3.355,\n",
       " 1.525,\n",
       " 2.15,\n",
       " 3.19,\n",
       " 3.77,\n",
       " 3.95,\n",
       " 4.38,\n",
       " 5.48,\n",
       " 5.505,\n",
       " 5.005,\n",
       " 5.355]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb236ee-406d-4579-a356-d7d0a47e9e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
